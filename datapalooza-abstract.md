# IBM Datapalooza, Denver - May, 2016

One of the advantages of Apache Spark is its ability to run in various environments, from your personal laptop to a large cluster. In terms of learning Spark or performing ad-hoc analysis, this means that you have the ability to tinker on your local machine, doing data analytics with your favorite Python packages, while also leveraging concurrency of the JVM.

In this talk, I'll show how to use Spark and the Jupyter Notebook (along with various Python packages: Pandas, Seaborn, etc.) to collect and analyze data from the public Twitter API.
